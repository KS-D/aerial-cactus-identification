{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cactus Identification Groundwork\n",
    "\n",
    "## The first steps of building a model with keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Dependencies\n",
    "import keras\n",
    "import os\n",
    "import glob\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How the files should be layed out in the pwd for the below code to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cactus-identification-earlywork.ipynb  \u001b[0m\u001b[01;34mtrain\u001b[0m/  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas to format the csv file, and make a data frame to label our data, because the pictures in the train/ directory are unlabeled. Building a data frame allows us to label the data from the train.csv file instead of sorting the photos into 2 directories. Below the first 10 photos are listed, along side their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id  has_cactus\n",
      "0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
      "1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n",
      "2  000d1e9a533f62e55c289303b072733d.jpg           1\n",
      "3  0011485b40695e9138e92d0b3fb55128.jpg           1\n",
      "4  0014d7a11e90b62848904c1418fc8cf2.jpg           1\n",
      "5  0017c3c18ddd57a2ea6f9848c79d83d2.jpg           1\n",
      "6  002134abf28af54575c18741b89dd2a4.jpg           0\n",
      "7  0024320f43bdd490562246435af4f90b.jpg           0\n",
      "8  002930423b9840e67e5a54afd4768a1e.jpg           1\n",
      "9  00351838ebf6dff6e53056e00a1e307c.jpg           1\n"
     ]
    }
   ],
   "source": [
    "data_frame = pd.read_csv('./train.csv')\n",
    "print(data_frame[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an ImageDataGenerator\n",
    "\n",
    "There are several steps that can be manipulated below: batch size, color, and the other parametors of the ImageDataGenerator class.\n",
    "\n",
    "A training set and validation set are created so that we can test a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images.\n",
      "Found 5500 images.\n"
     ]
    }
   ],
   "source": [
    "columns = [\"has_cactus\"]\n",
    "\n",
    "datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=data_frame[:12000],\n",
    "directory=\"./train\",\n",
    "x_col=\"id\",\n",
    "y_col=columns,\n",
    "batch_size=32,\n",
    "seed=6,\n",
    "shuffle=True,\n",
    "class_mode=\"other\",\n",
    "target_size=(32,32))\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "dataframe=data_frame[12000:],\n",
    "directory=\"./train\",\n",
    "x_col=\"id\",\n",
    "y_col=columns,\n",
    "batch_size=32,\n",
    "seed=6,\n",
    "shuffle=True,\n",
    "class_mode=\"other\",\n",
    "target_size=(32,32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fields of the model can be referenced in print statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb\n",
      "channels_last\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.color_mode)\n",
    "print(train_generator.data_format)\n",
    "print(train_generator.image_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Network adapted from a keras example to test to see if the data had been properly imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kyle/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/kyle/Documents/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kyle/Documents/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - 11s 340ms/step - loss: 0.5639 - acc: 0.7383 - val_loss: 0.5044 - val_acc: 0.7656\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.4939 - acc: 0.7354 - val_loss: 0.4339 - val_acc: 0.7314\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.4041 - acc: 0.7822 - val_loss: 0.3193 - val_acc: 0.8984\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.3065 - acc: 0.8721 - val_loss: 0.2486 - val_acc: 0.9043\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.2674 - acc: 0.9014 - val_loss: 0.2010 - val_acc: 0.9277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f64a9358588>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator, \n",
    "                    steps_per_epoch=32, \n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=32,\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
